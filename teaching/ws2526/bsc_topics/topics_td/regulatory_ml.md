---
layout: entitled
title: Regulatory AI
---

**Motivation**: Regulatory AI explores how technical systems can support accountability, transparency, and compliance in machine learning. The goal is to design models and data pipelines that can be audited, constrained, or certified: turning legal and ethical requirements into computable properties. This connects ML research on robustness, interpretability, and verification with questions of governance and oversight.

**Overview**:

- Montreal AI Ethics Institute *"Series on the regulatory landscape of AI"*. ([montrealethics.ai](https://montrealethics.ai/category/special-topics/regulatory-landscape/))
- NeurIPS 2024 RegML Workshop *"Regulatable ML: Towards Bridging the Gaps between Machine Learning Research and Regulations"*. ([neurips.cc](https://neurips.cc/virtual/2024/workshop/84736))
- DeepMind blog: *“Exploring institutions for global AI governance”*, 2023.  
  ([deepmind.google](https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance))

**Papers and topics**:

- data governance frameworks for frontier AI models (Hausenloy, J., McClements, M. & Thakur, P. "Towards Data Governance of Frontier AI Models." NeurIPS RegML 2024)
- algorithmic auditing and accountability frameworks (Raji, I. D., Smart, A., White, R., Mitchell, M., Gebru, T. et al. "Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing." FAccT 2020)
- data governance concerns for generative AI systems (Aaronson SA. "Data Disquiet: Concerns about the Governance of Data for Generative AI." CIGI 2024)
