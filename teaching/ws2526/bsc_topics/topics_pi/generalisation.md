---
layout: entitled
title: Generalisation
---

**Motivation**: The ability of a model to adapt and perform well on new data is crucial. A model which generalises not only performs well on the training set, but on unseen data as well. Understanding and characterising why and how deep learning can generalise well is still an open question.

**Overview**:

- notes on generalisation (Prof. Roger Grosse) [(link)](https://www.cs.toronto.edu/~lczhang/321/notes/notes09.pdf)
- generalisation and overfitting [(youtube-link)](https://www.youtube.com/watch?v=pFWiauHOFpY)

**Papers and topics**:

- Brilliantov, Souza, Garg. Compositional PAC-Bayes:  Generalization of GNNs with persistence and beyond. NeurIPS, 2024. 
- Rauchwerger et al. Generalization, Expressivity, and Universality of Graph Neural Networks on Attributed Graphs. ICLR, 2025. 
- Behboodi, Cesa, Cohen. A PAC-Bayesian Generalization Bound for Equivariant Networks. NeurIPS, 2022. 
