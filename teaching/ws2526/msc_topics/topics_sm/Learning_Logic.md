---
layout: entitled
title: Learning Logically Definable Concepts 
---

**Motivation**: Ability to learn logically definable concepts from labelled data is a theoretical model of Machine Learning which is explainable by design, and integrates ideas from both logic (especially finite model theory) and PAC Learning. 

**Overview**:

- Shai Ben-David and Shai Shalev-Shwartz. Understanding Machine Learning. Chapter 2,3
- Shai Ben-David Lectures. [(youtube-link)](https://www.youtube.com/watch?v=aILazXK059Y&list=PLFze15KrfxbH8SE4FgOHpMSY1h5HiRLMm&index=2) Lecture 1,2,3


**Papers and topics**:

- Kaifu Wang, Efthymia Tsamoura, Dan Roth. On learning latent models with multi-instance weak supervision. Neurips 2024
- Sam Adam-Day, Theodor Mihai Iliant, İsmail İlkan Ceylan. Zero-One Laws of Graph Neural Networks. 2024
- Sam Adam-Day, Michael Benedikt, İsmail İlkan Ceylan, Ben Finkelshtein. Graph neural network outputs are almost surely asymptotically constant. 2024
- Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, Jure Leskovec. GNNExplainer: Generating Explanations for Graph Neural Networks. 2019












