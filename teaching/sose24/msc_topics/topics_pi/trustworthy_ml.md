---
layout: entitled
title: Trustworthy ML
---

**Motivation**: Machine learning systems are ubiquitous and it is necessary to make sure they behave as intended. In particular, trustworthiness can be achieved by means of privacy-preserving, robust, and explainable algorithms. We focus here on the desideratum of privacy.

**Overview**:
- General: What does it mean for ML to be trustworthy? ([youtube-link](https://www.youtube.com/watch?v=UpGgIqLhaqo))
- General: Trustworthy ML (Kush R. Varshney) ([link](http://www.trustworthymachinelearning.com/))
- Differential privacy: Chapter 2 of: Dwork, Cynthia, and Aaron Roth. "The algorithmic foundations of differential privacy." Found. Trends Theor. Comput. Sci. 2014

**Papers and topics**:
- differential privacy and deep learning (Chen, Xiangyi, Steven Z. Wu, and Mingyi Hong. "Understanding gradient clipping in private SGD: A geometric perspective." NeurIPS 2020)
- data reconstruction and differential privacy (Hayes, Jamie, Saeed Mahloujifar, and Borja Balle. "Bounding Training Data Reconstruction in DP-SGD." arXiv, 2023).
- (extensions of) gaussian mechanism (Balle, Borja, and Yu-Xiang Wang. "Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising." International Conference on Machine Learning. PMLR, 2018)
- high-dimensional mean estimation which is robust and private (Narayanan, Shyam, Vahab Mirrokni, and Hossein Esfandiari. "Tight and Robust Private Mean Estimation with Few Users." ICML. PMLR, 2022.)
- private learnability (Alon, Noga, et al. "A Unified Characterization of Private Learnability via Graph Theory." arXiv, 2023)
- graph statistics under differential privacy (Laeuchli, Jesse, Yunior Ram√≠rez-Cruz, and Rolando Trujillo-Rasua. "Analysis of centrality measures under differential privacy models." Applied Mathematics and Computation, 2022)
