---
layout: entitled
title: Investigating Bias in Graph-based Recommender Systems
---


**CONTEXT**: Bias in ML models is a very important part of ML research
which tries to identify and reduce implicit biases such as gender or
racial bias. While there has been a plethora of different algorithms and
methods to debias deep neural networks (e.g., debiasing Recommender
Systems, Large Language Models), there is still plenty of room to
explore, especially for graph-based models such as GNNs. While recent
work has investigated bias on item level such as popularity bias,
user-centric bias is yet to be explored. The research question in focus
is two-fold: (1) Can we identify unwanted bias related to sensitive user
attributes in the node features of a GNN based recommender system? And
if yes, (2) how can we mitigate unwanted bias in user embeddings for a
GNN based recommender system?

**SUPERVISOR**: David Penz ( <david.penz@tuwien.ac.at> )