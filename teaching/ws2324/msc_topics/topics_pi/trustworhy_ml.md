---
layout: entitled
title: Trustworthy ML
---

**Motivation**: Machine learning systems are ubiquitous and it is necessary to make sure they behave as intended. In particular, trustworthiness can be achieved by means of privacy-preserving, robust, and explainable algorithms.

**Overview**:
- General: What does it mean for ML to be trustworthy? ([youtube-link](https://www.youtube.com/watch?v=UpGgIqLhaqo))
- General: Trustworthy ML (Kush R. Varshney) ([link](http://www.trustworthymachinelearning.com/))
- Differential privacy: Chapter 2 of: Dwork, Cynthia, and Aaron Roth. "The algorithmic foundations of differential privacy." Found. Trends Theor. Comput. Sci. 2014
- Explainability: Došilović, Filip Karlo, Mario Brčić, and Nikica Hlupić. "Explainable artificial intelligence: A survey." MIPRO 2018

**Papers and topics**:
- Differential privacy:
  - differential privacy and deep learning (Chen, Xiangyi, Steven Z. Wu, and Mingyi Hong. "Understanding gradient clipping in private SGD: A geometric perspective." NeurIPS 2020)
  - data reconstruction and differential privacy (Hayes, Jamie, Saeed Mahloujifar, and Borja Balle. "Bounding Training Data Reconstruction in DP-SGD." arXiv, 2023).
  - (extensions of) gaussian mechanism (Balle, Borja, and Yu-Xiang Wang. "Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising." International Conference on Machine Learning. PMLR, 2018)
  - high-dimensional mean estimation which is robust and private (Narayanan, Shyam, Vahab Mirrokni, and Hossein Esfandiari. "Tight and Robust Private Mean Estimation with Few Users." ICML. PMLR, 2022.)
- Explainability:
  - nonlinear classifiers (Montavon, Grégoire, et al. "Explaining nonlinear classification decisions with deep taylor decomposition." Pattern recognition, 2017)
- Robustness:
  - GNN structural perturbations (Wang, et al. "Certified robustness of graph neural networks against adversarial structural perturbation." ACM SIGKDD, 2021)
