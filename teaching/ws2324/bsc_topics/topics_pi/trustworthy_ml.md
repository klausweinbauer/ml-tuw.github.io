---
layout: entitled
title: Trustworthy ML
---

**Motivation**: Machine learning systems are ubiquitous and it is necessary to make sure they behave as intended. In particular, trustworthiness can be achieved by means of privacy-preserving, robust, and explainable algorithms.

**Overview**:

- General: What does it mean for ML to be trustworthy? [(youtube-link)](https://www.youtube.com/watch?v=UpGgIqLhaqo)
- General: Trustworthy ML (Kush R. Varshney) [(link)](http://www.trustworthymachinelearning.com/)
- Differential privacy: Chapter 2 of: Dwork, Cynthia, and Aaron Roth. "The algorithmic foundations of differential privacy." Found. Trends Theor. Comput. Sci. 9.3-4 2014
- Explainability: Samek, Wojciech, and Klaus-Robert MÃ¼ller. "Towards explainable artificial intelligence." Explainable AI: interpreting, explaining and visualizing deep learning." Springer, Cham, 2019

**Papers and topics**:

- interpreting model predictions
  - Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. ""Why should i trust you?" Explaining the predictions of any classifier." ACM SIGKDD 2016
  - Lundberg, Scott M., and Su-In Lee. "A unified approach to interpreting model predictions." NeurIPS 2017
 
- reliability of explanation methods
  - Kumar, I. Elizabeth, et al. "Problems with Shapley-value-based explanations as feature importance measures." ICML, 2020.
 
- robustness against attacks and adversaries
  - Jagielski, Matthew, et al. "Manipulating machine learning: Poisoning attacks and countermeasures for regression learning." 2018 IEEE Symposium on Security and Privacy (SP). IEEE, 2018.
  - Carmon, Yair, et al. "Unlabeled data improves adversarial robustness." NeurIPS 2019.
 
- differential privacy
  - Abadi, Martin, et al. "Deep learning with differential privacy." Proceedings of the 2016 ACM SIGSAC conference on computer and communications security. 2016.
  - Patel, Neel, Reza Shokri, and Yair Zick. "Model explanations with differential privacy." 2022 ACM Conference on Fairness, Accountability, and Transparency. 2022.
