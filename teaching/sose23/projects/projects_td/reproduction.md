---
layout: entitled
title: Reproducibility of ML papers
---

**Type**: Experimental

**Recommended Skills**: Some programming experience, ideally some experience with standard machine learning libraries such as PyTorch.

**Task**: Reproduce the results of a machine learning paper.

**Context**: Reproducibility, i.e., obtaining similar output using the same data, is a critical quality in research. Unfortunately, this is often not the case.

**Suggested approach**: Choose a paper from one of the following venues: NeurIPS, ICML, ICLR, ECML, JMLR, MLJ. Please do no just re-use existing code! (i.e., re-implement in a different programming language/library, or implement methods from multiple papers to perform a comparison.)

**Related work**:
- NeurIPS reproducibility program (Pineau, Joelle, et al. "Improving reproducibility in machine learning research (a report from the NeurIPS 2019 reproducibility program)." JMLR, 2021)
- quantifying reproducibility (Raff. "A step toward quantifying independently reproducible machine learning research." NeurIPS 2019)
- [https://reproducedpapers.org/](https://reproducedpapers.org/)
 
**Advisor**: Depends on paper
