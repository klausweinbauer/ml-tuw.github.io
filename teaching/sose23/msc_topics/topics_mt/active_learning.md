---
layout: entitled
title: Active Learning
---

**Motivation**: In active learning, the learning algorithm is allowed to select the data points it wants to see labelled, for example, where it is most uncertain. The goal is to reduce the labelling effort. This is useful in applications where unlabelled data is abundant, yet labels are scarce, such as node classification in social networks, drug discovery, and autonomous driving.

**Overview**:

- chapter 1 "Automating inquiry" of Burr Settles' "Active learning" book, 2012.
- introduction and recent research: Rob Nowak and Steve Hanneke - ICML 2019 tutorial [(youtube-link)](https://youtube.videoken.com/embed/0TADiY7iPAc)

**Papers and topics**:

- active learning with comparison queries (Kane, D. M., Lovett, S., Moran, S., & Zhang, J.  "Active classification with comparison queries." FOCS 2017)
- sample complexity in active learning (Maria-Florina Balcan, Steve Hanneke, and Jennifer Wortman Vaughan "The true sample complexity of active learning." Machine Learning 2010)
- bounded memory active learning (M. Hopkins, D. Kane, S. Lovett & M. Moshkovitz. "Bounded memory active learning through enriched queries." COLT 2021)
