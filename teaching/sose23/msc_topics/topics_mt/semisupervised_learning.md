---
layout: entitled
title: Semi-supervised Learning
---

**Motivation**: Semi-supervised learning uses labelled and to be able to train classifiers with fewer labels. This is useful in applications where unlabelled data is abundant, yet labels are scarce, such as node classification in social networks, drug discovery, and autonomous driving.

**Overview**:

- first chapter/introduction of "Semi-supervised learning" (SSL) by Olivier Chapelle, Bernhard Sch√∂lkopf, and Alexander Zien, 2006 [(pdf)](http://olivier.chapelle.cc/ssl-book/ssl_toc.pdf)
- introduction to semi-supervised learning: Tom Mitchell - Carnegie Mellon University 2011 [(youtube-link)](https://www.youtube.com/watch?v=OMRlnKupsXM)

**Papers and topics**:

- transductive support vector machines (chapter 6 in SSL by Thorsten Joachims)
- large-margin semi-supervised learning (Wang, et al. "On efficient large margin semisupervised learning: method and theory." Journal of machine learning research 2009)
- PAC model for semi-supervised learning (chapter 22 of SSL by Maria-Florina Balcan and Avrim Blum)
- generalization error bounds (Rigollet. "Generalization error bounds in semi-supervised classification under the cluster assumption." Journal of machine learning research 2007)
- regularization and semi-supervised learning on graphs (Belkin, et al. "Regularization and semi-supervised learning on large graphs." COLT 2004)
- manifold regularization (Belkin, et al. "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples." Journal of machine learning research 2006)
